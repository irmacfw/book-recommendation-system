{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68329238-301b-4926-898b-23d8902626c5",
   "metadata": {},
   "source": [
    "### üìò Notebook 03 ‚Äî Feature Engineering & Clustering\n",
    "\n",
    "In this notebook, we move from **data preparation** to **unsupervised learning**.  \n",
    "Using the cleaned dataset (`books_final_1000.csv`), we‚Äôll extract key features such as ratings, price, and genre to group similar books with **K-Means clustering**.\n",
    "\n",
    "**Goals:**\n",
    "- Prepare numerical and categorical features  \n",
    "- Apply **K-Means** and evaluate with **Elbow Method** & **Silhouette Score**  \n",
    "- Visualize and interpret clusters for future recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436f659a-f4e5-4af3-a457-08c4452d07dd",
   "metadata": {},
   "source": [
    "### Step 1 ‚Äî Imports & Setup\n",
    "\n",
    "Import core libraries for clustering and visualization,  \n",
    "reload the shared `functions.py` module, and verify that all paths from `config.yaml` are available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f027a062-e911-468c-8c82-bcc84cd11f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 1 ‚Äî Imports & Setup \n",
    "# ============================================================\n",
    "\n",
    "# --- System and project setup ---\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add 'notebooks' folder to path (functions.py lives there)\n",
    "sys.path.append(\"notebooks\")\n",
    "\n",
    "# --- Load shared utilities ---\n",
    "from functions import load_config, ensure_directories\n",
    "\n",
    "# --- ML and visualization libraries ---\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# --- Visualization settings (como en clase) ---\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\")\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
    "\n",
    "# --- Load configuration and verify folders ---\n",
    "config_path = Path(\"..\") / \"config.yaml\"\n",
    "config = load_config(config_path)\n",
    "ensure_directories(config[\"paths\"])\n",
    "\n",
    "print(\"‚úÖ Environment ready ‚Äî config loaded and directories verified.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf9a4e9-fb7b-4eff-a38a-6144010179be",
   "metadata": {},
   "source": [
    "### Step 2 ‚Äî Load Final Dataset  \n",
    "\n",
    "Load the cleaned and standardized dataset (`books_final_1000.csv`) generated in the previous notebook.  \n",
    "We‚Äôll inspect its structure, check column types, and verify that all key variables are ready for feature preparation.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cc82b0-b7dd-495a-99a2-9b71470a1098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 2 ‚Äî Load Final Dataset\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Load dataset from data/clean ---\n",
    "data_path = Path(\"..\") / config[\"paths\"][\"data_clean\"] / \"books_final_1000.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"‚úÖ Dataset loaded successfully: {data_path}\")\n",
    "print(f\"Shape: {df.shape}\\n\")\n",
    "\n",
    "# --- Quick overview ---\n",
    "display(df.head(5))\n",
    "\n",
    "# --- Basic info and types ---\n",
    "print(\"\\nüîç DataFrame Info:\")\n",
    "print(df.info())\n",
    "\n",
    "# --- Missing values summary ---\n",
    "missing_summary = df.isna().sum()\n",
    "missing_summary = missing_summary[missing_summary > 0]\n",
    "\n",
    "if not missing_summary.empty:\n",
    "    print(\"\\n‚ö†Ô∏è Missing values summary:\")\n",
    "    print(missing_summary)\n",
    "else:\n",
    "    print(\"\\n‚úÖ No missing values detected.\")\n",
    "\n",
    "# --- Optional: Unique values check (for categorical columns) ---\n",
    "print(\"\\nüß© Unique values per column:\")\n",
    "print(df.nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b3587b-bc60-444b-97b0-23dc52c64bb0",
   "metadata": {},
   "source": [
    "### Step 3 ‚Äî Feature Preparation\n",
    "\n",
    "Select relevant features for clustering:\n",
    "- `avg_rating` (numerical)\n",
    "- `price` (numerical)\n",
    "- `genre` (categorical)\n",
    "\n",
    "We‚Äôll:\n",
    "1. Fill missing prices with the median value  \n",
    "2. Encode `genre` using One-Hot Encoding  \n",
    "3. Standardize numerical features with `StandardScaler`  \n",
    "4. Combine all into a clean feature matrix for K-Means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2490fb66-6f28-440f-b9bd-850b6f404913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 3 ‚Äî Feature Preparation (Fix Missing Price Fill)\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# --- Select relevant columns ---\n",
    "features = [\"avg_rating\", \"price\", \"genre\"]\n",
    "df_features = df[features].copy()\n",
    "\n",
    "# --- Handle missing prices ---\n",
    "median_price = df_features[\"price\"].median()\n",
    "df_features[\"price\"] = df_features[\"price\"].fillna(median_price)\n",
    "\n",
    "# --- Reflect the filled prices back into df ---\n",
    "df[\"price\"] = df[\"price\"].fillna(median_price)\n",
    "print(f\"Filled missing 'price' values with median: {median_price:.2f}\")\n",
    "\n",
    "# --- One-Hot Encode 'genre' ---\n",
    "df_encoded = pd.get_dummies(df_features, columns=[\"genre\"], drop_first=True)\n",
    "print(f\"Encoded dataset has {df_encoded.shape[1]} columns after one-hot encoding.\")\n",
    "\n",
    "# --- Standardize numeric columns ---\n",
    "scaler = StandardScaler()\n",
    "numeric_cols = [\"avg_rating\", \"price\"]\n",
    "df_encoded[numeric_cols] = scaler.fit_transform(df_encoded[numeric_cols])\n",
    "print(\"üìè Numeric columns standardized (avg_rating, price).\")\n",
    "\n",
    "# --- Optional sanity check ---\n",
    "missing_check = df_encoded.isna().sum().sum()\n",
    "if missing_check == 0:\n",
    "    print(\"‚úÖ No missing values remain in feature matrix.\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è {missing_check} missing values still present ‚Äî check source data.\")\n",
    "\n",
    "# --- Assign to feature matrix for clustering ---\n",
    "X = df_encoded.values\n",
    "\n",
    "print(f\"\\n‚úÖ Feature matrix ready for clustering. Shape: {df_encoded.shape}\")\n",
    "\n",
    "# --- Quick preview ---\n",
    "display(df_encoded.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610698bf-5f3d-4739-8d38-971a5d463a8c",
   "metadata": {},
   "source": [
    "### Step 4 ‚Äî K-Means Clustering (Elbow & Silhouette Method)\n",
    "\n",
    "We‚Äôll apply **K-Means clustering** to group similar books based on their features.  \n",
    "To choose the optimal number of clusters (`k`), we‚Äôll use:\n",
    "- the **Elbow Method** (inertia plot), and  \n",
    "- the **Silhouette Score** (cluster separation quality).  \n",
    "\n",
    "This helps identify a balance between compactness and separation of clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dabbef9-51d6-4e98-8493-e9b732725cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 4 ‚Äî K-Means Clustering (Elbow & Silhouette Method)\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Feature matrix ---\n",
    "X = df_encoded.copy()\n",
    "\n",
    "# --- Initialize lists ---\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "print(\"üîπ Running K-Means for k = 2 to 10...\\n\")\n",
    "\n",
    "# --- Run K-Means across different k values ---\n",
    "for k in K_range:\n",
    "    try:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        kmeans.fit(X)\n",
    "        inertias.append(kmeans.inertia_)\n",
    "        score = silhouette_score(X, kmeans.labels_)\n",
    "        silhouette_scores.append(score)\n",
    "        print(f\"‚úÖ k={k} ‚Äî Inertia={kmeans.inertia_:.2f}, Silhouette={score:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error for k={k}: {e}\")\n",
    "        inertias.append(np.nan)\n",
    "        silhouette_scores.append(np.nan)\n",
    "\n",
    "# --- Determine best k by silhouette score ---\n",
    "valid_scores = [s for s in silhouette_scores if not np.isnan(s)]\n",
    "best_k = K_range[silhouette_scores.index(max(valid_scores))]\n",
    "print(f\"\\nüåü Best k by silhouette score: {best_k}\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# üìà Visualization ‚Äî Elbow & Silhouette\n",
    "# ============================================================\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(11, 4))\n",
    "\n",
    "# --- Elbow Method ---\n",
    "ax1.plot(K_range, inertias, marker='o', color='steelblue')\n",
    "ax1.set_title(\"Elbow Method ‚Äî K-Means Inertia\", fontsize=11)\n",
    "ax1.set_xlabel(\"Number of Clusters (k)\")\n",
    "ax1.set_ylabel(\"Inertia\")\n",
    "\n",
    "# --- Silhouette Scores ---\n",
    "ax2.plot(K_range, silhouette_scores, marker='o', color='orange')\n",
    "ax2.set_title(\"Silhouette Scores by Number of Clusters\", fontsize=11)\n",
    "ax2.set_xlabel(\"Number of Clusters (k)\")\n",
    "ax2.set_ylabel(\"Silhouette Score\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# üíæ Save Results\n",
    "# ============================================================\n",
    "\n",
    "viz_path = Path(\"..\") / \"visualizations\"\n",
    "viz_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "fig.savefig(viz_path / \"kmeans_elbow_silhouette_combined.png\", dpi=300, bbox_inches=\"tight\")\n",
    "print(f\"üíæ Combined plot saved ‚Üí {viz_path / 'kmeans_elbow_silhouette_combined.png'}\")\n",
    "\n",
    "metrics_path = Path(\"..\") / \"data\" / \"clean\"\n",
    "metrics_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    \"k\": list(K_range),\n",
    "    \"inertia\": inertias,\n",
    "    \"silhouette\": silhouette_scores\n",
    "})\n",
    "metrics_df.to_csv(metrics_path / \"kmeans_metrics.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"üíæ Metrics saved ‚Üí {metrics_path / 'kmeans_metrics.csv'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707b605c-79de-41e4-bea2-567c0891b1ec",
   "metadata": {},
   "source": [
    "### ============================================================\n",
    "### Step 4.1 ‚Äî Interpretation of Clustering Metrics\n",
    "### ============================================================\n",
    "\n",
    "The Elbow Method shows a sharp drop in inertia from k = 2 to k = 3,\n",
    "after which the curve flattens ‚Äî suggesting that adding more clusters\n",
    "beyond k = 2 provides limited improvement in compactness.\n",
    "\n",
    "The Silhouette Scores confirm that:\n",
    "- k = 2 achieves the highest separation (‚âà 0.75),\n",
    "  meaning clusters are well-defined and internally cohesive.\n",
    "- Higher k values slightly decrease silhouette quality,\n",
    "  indicating overlapping or less distinct groups.\n",
    "\n",
    "üìä **Decision:** We‚Äôll proceed with **k = 2 clusters**, as it offers \n",
    "a strong balance between compactness and separation.\n",
    "\n",
    "üß† **Interpretation:**\n",
    "Each book is represented by numerical and categorical features such as\n",
    "*avg_rating*, *genre*, and *price*.  \n",
    "K-Means groups books with similar characteristics into two main clusters ‚Äî\n",
    "possibly reflecting broad patterns such as\n",
    "‚Äúhigh-rated / premium‚Äù vs. ‚Äúlower-rated / affordable‚Äù categories,\n",
    "which can later inform recommendation logic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eff8eed-a010-4a82-9d0f-52732d1c8f70",
   "metadata": {},
   "source": [
    "### Step 5 ‚Äî Apply Final K-Means & Visualize Clusters (PCA 2D Projection)\n",
    "\n",
    "Now that we‚Äôve decided on **k = 2 clusters**, we‚Äôll train the final K-Means model.  \n",
    "Then, we‚Äôll apply **Principal Component Analysis (PCA)** to reduce the high-dimensional\n",
    "feature space into **two components**, allowing us to visualize the book clusters in 2D.  \n",
    "\n",
    "This helps identify group patterns ‚Äî for example,  \n",
    "books that share similar ratings, prices, or genres might fall close together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fa2b43-2197-433e-87b4-3016cce42d21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 5 ‚Äî Apply Final K-Means & Visualize Clusters (PCA 2D)\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# --- Final number of clusters ---\n",
    "k_final = 2\n",
    "print(f\"üè∑Ô∏è Applying final K-Means model with k = {k_final}...\\n\")\n",
    "\n",
    "# --- Scale features ---\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_encoded)\n",
    "\n",
    "# --- Train K-Means ---\n",
    "kmeans_final = KMeans(n_clusters=k_final, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans_final.fit_predict(X_scaled)\n",
    "\n",
    "# --- Assign clusters safely ---\n",
    "df = df.copy()\n",
    "df[\"cluster\"] = cluster_labels\n",
    "\n",
    "# --- PCA for visualization ---\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "pca_components = pca.fit_transform(X_scaled)\n",
    "df[\"pca_1\"] = pca_components[:, 0]\n",
    "df[\"pca_2\"] = pca_components[:, 1]\n",
    "\n",
    "# ============================================================\n",
    "# üé® Enhanced Visualization ‚Äî PCA 2D Scatter Plot\n",
    "# ============================================================\n",
    "\n",
    "fig_pca, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.scatterplot(\n",
    "    data=df,\n",
    "    x=\"pca_1\", y=\"pca_2\",\n",
    "    hue=\"cluster\",\n",
    "    palette=\"Set2\",\n",
    "    s=65,\n",
    "    alpha=0.85,\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=0.7,\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title(f\"Book Clusters ‚Äî PCA 2D Projection (k = {k_final})\", fontsize=13, pad=10)\n",
    "ax.set_xlabel(\"Principal Component 1\")\n",
    "ax.set_ylabel(\"Principal Component 2\")\n",
    "ax.legend(title=\"Cluster\", loc=\"best\", fontsize=9)\n",
    "ax.grid(alpha=0.25, linestyle=\"--\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# üíæ Save Plot\n",
    "# ============================================================\n",
    "\n",
    "viz_path = Path(\"..\") / \"visualizations\"\n",
    "fig_pca.savefig(viz_path / f\"pca_clusters_k{k_final}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "print(f\"Clustering completed. {df['cluster'].nunique()} clusters created.\")\n",
    "print(f\"PCA cluster visualization saved ‚Üí {viz_path / f'pca_clusters_k{k_final}.png'}\\n\")\n",
    "\n",
    "# --- Preview sample ---\n",
    "display(df[[\"title\", \"author\", \"avg_rating\", \"genre\", \"price\", \"cluster\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebb5a88-c169-4c92-a58a-19e399542fba",
   "metadata": {},
   "source": [
    "### üìä Interpretation of Final Clusters\n",
    "\n",
    "The 2-cluster configuration reveals two distinct groups of books based primarily on their average rating and price level.\n",
    "Although genre information wasn‚Äôt directly used in the clustering, it helps describe each cluster‚Äôs general tendencies.\n",
    "\n",
    "üìò Cluster 0 (Green):\n",
    "\n",
    "Contains books with higher average prices, sometimes reaching premium levels.\n",
    "\n",
    "Average ratings remain solid (‚âà 4.1), but these titles show greater variability in pricing, suggesting a mix of editions or market positions.\n",
    "\n",
    "The genre distribution is more diverse, often including specialized or non-mainstream categories.\n",
    "\n",
    "üìô Cluster 1 (Orange):\n",
    "\n",
    "Concentrates books with moderate, consistent prices (around the dataset‚Äôs median ‚âà 9 EUR).\n",
    "\n",
    "Also maintains strong average ratings (‚âà 4.1‚Äì4.3), representing a stable quality baseline.\n",
    "\n",
    "This group likely includes popular, widely accessible titles, often in fiction.\n",
    "\n",
    "üß† Interpretation:\n",
    "The model separates books mainly by price range and rating consistency:\n",
    "\n",
    "Cluster 1 groups books that are affordable and evenly rated, suggesting mainstream popularity.\n",
    "\n",
    "Cluster 0 includes higher-priced or more varied titles, pointing toward specialized or premium segments.\n",
    "\n",
    "This segmentation provides a useful foundation for recommendation logic ‚Äî books within the same cluster share similar value and rating profiles, which can guide price-sensitive or quality-focused suggestions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7170f744-bce7-4ec8-938c-bf6905a6b626",
   "metadata": {},
   "source": [
    "### Step 5.1 ‚Äî Analyze Cluster Centroids\n",
    "\n",
    "Let‚Äôs inspect the numerical centroids of each cluster to understand\n",
    "how books are grouped ‚Äî for example, by their average rating or price.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d9f7a4-4d57-453f-93aa-1985251ba360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 5.1 ‚Äî Analyze Cluster Centroids\n",
    "# ============================================================\n",
    "\n",
    "\"\"\"\n",
    "üéØ Step 5.1 ‚Äî Analyze Cluster Centroids\n",
    "Resumir los valores promedio de rating, precio y el g√©nero predominante\n",
    "para entender las caracter√≠sticas principales de cada cluster.\n",
    "\"\"\"\n",
    "\n",
    "cluster_centroids = (\n",
    "    df.groupby(\"cluster\")\n",
    "    .agg({\n",
    "        \"avg_rating\": \"mean\",\n",
    "        \"price\": \"mean\",\n",
    "        \"genre\": lambda x: x.mode().iloc[0] if not x.mode().empty else \"Unknown\"\n",
    "    })\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "# --- Add cluster sizes ---\n",
    "cluster_counts = df[\"cluster\"].value_counts().sort_index()\n",
    "cluster_centroids[\"count\"] = cluster_counts.values\n",
    "\n",
    "print(\"üìä Cluster Centroids Summary:\\n\")\n",
    "display(cluster_centroids)\n",
    "\n",
    "print(\"\\nüß≠ Interpretation Guide:\")\n",
    "print(\"- avg_rating ‚Üí Average book rating per cluster.\")\n",
    "print(\"- price ‚Üí Mean price, useful to detect premium vs. budget titles.\")\n",
    "print(\"- genre ‚Üí Most common genre in each cluster.\")\n",
    "print(\"- count ‚Üí Number of books in each cluster.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7d7919-8047-4653-ba31-41ab12585de5",
   "metadata": {},
   "source": [
    "### ============================================================\n",
    "### Step 5.2 ‚Äî Cluster Interpretation & Summary\n",
    "### ============================================================\n",
    "\n",
    "üß≠ **Interpretation**\n",
    "\n",
    "**Cluster 0 ‚Äî ‚ÄúDiverse & Low-Data Group‚Äù**  \n",
    "Books in this cluster display greater variability and include several entries\n",
    "with missing or undefined genre information (often labeled as *Unknown*).  \n",
    "Average prices are slightly lower or absent, and the group blends fiction with\n",
    "a few non-fiction or academic titles.  \n",
    "These books may represent **niche or irregular records** ‚Äî titles with limited metadata,\n",
    "specialized topics, or editions without consistent pricing.\n",
    "\n",
    "**Cluster 1 ‚Äî ‚ÄúMainstream & Popular Fiction‚Äù**  \n",
    "This cluster gathers the majority of the dataset, dominated by **Fiction**\n",
    "and related genres.  \n",
    "Books here show **consistent prices**, slightly **higher average ratings** (‚âà 4.1‚Äì4.3),\n",
    "and reflect the **core of widely read, well-rated works** ‚Äî from bestsellers\n",
    "to recognized literary classics.\n",
    "\n",
    "üí¨ **Overall Insight**  \n",
    "With the expanded dataset of ‚âà 1 100 books, the clustering naturally separates titles\n",
    "into two broad groups:\n",
    "\n",
    "- A **mainstream segment** (Cluster 1) capturing structured, popular fiction.  \n",
    "- A **diverse / incomplete-metadata segment** (Cluster 0) containing outliers\n",
    "  or books missing genre and pricing details.\n",
    "\n",
    "This suggests that **genre completeness and pricing consistency**\n",
    "are major differentiators in how the model groups books.  \n",
    "Future data enrichment ‚Äî for instance, filling missing *genre* values through\n",
    "an API like *Google Books* ‚Äî could sharpen these boundaries\n",
    "and yield finer thematic clusters for recommendation logic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db1fc3c-0a01-4b19-9108-35d25c40e2c4",
   "metadata": {},
   "source": [
    "## Step 6 ‚Äî Export Final Clustered Dataset\n",
    "\n",
    "We‚Äôll now export the final dataset including the cluster labels (`cluster`)\n",
    "and PCA coordinates (`pca_1`, `pca_2`) for visualization and further analysis.  \n",
    "This dataset can be used in **Tableau**, **Power BI**, or in the next notebook\n",
    "for building the **Recommendation System**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9798ed3-9221-4ed1-b60b-6f9d624ae5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 6 ‚Äî Export Final Clustered Dataset & Cluster Summary\n",
    "# ============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# --- Define export paths ---\n",
    "data_clean_path = Path(\"..\") / config[\"paths\"][\"data_clean\"]\n",
    "viz_path = Path(\"..\") / \"visualizations\"\n",
    "data_clean_path.mkdir(parents=True, exist_ok=True)\n",
    "viz_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Export final dataset ---\n",
    "final_cluster_path = data_clean_path / \"books_clustered_final.csv\"\n",
    "\n",
    "export_cols = [\n",
    "    \"title\", \"author\", \"avg_rating\", \"genre\", \"price\", \"currency\",\n",
    "    \"cover_url\", \"link\", \"cluster\", \"pca_1\", \"pca_2\"\n",
    "]\n",
    "\n",
    "df[export_cols].to_csv(final_cluster_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"üíæ Final clustered dataset saved successfully ‚Üí {final_cluster_path.resolve()}\")\n",
    "\n",
    "# --- Quick preview ---\n",
    "print(\"\\nüìò Sample of exported dataset:\")\n",
    "display(df[export_cols].head(10))\n",
    "\n",
    "# ============================================================\n",
    "# üìä Cluster Summary (for visualization or presentation)\n",
    "# ============================================================\n",
    "\n",
    "cluster_summary = (\n",
    "    df.groupby(\"cluster\")\n",
    "    .agg({\n",
    "        \"avg_rating\": \"mean\",\n",
    "        \"price\": \"mean\",\n",
    "        \"genre\": lambda x: x.mode().iloc[0] if not x.mode().empty else \"Unknown\"\n",
    "    })\n",
    "    .round(2)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# --- Add cluster sizes ---\n",
    "cluster_summary[\"count\"] = df[\"cluster\"].value_counts().sort_index().values\n",
    "\n",
    "# --- Save summary ---\n",
    "summary_path = data_clean_path / \"cluster_summary.csv\"\n",
    "cluster_summary.to_csv(summary_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"\\nüìó Cluster Summary:\")\n",
    "display(cluster_summary)\n",
    "\n",
    "print(f\"\\nüíæ Cluster summary saved ‚Üí {summary_path.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d624561-13bb-46e2-a0e3-4a170d8e5aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# üìä Cluster Summary Table ‚Äî Final Styled Version (Updated for k = 2)\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# --- Use real summary from notebook ---\n",
    "cluster_summary = pd.DataFrame({\n",
    "    \"Cluster\": [0, 1],\n",
    "    \"Dominant Genre\": [\"Unknown\", \"Fiction\"],\n",
    "    \"Avg Rating\": [4.05, 4.21],\n",
    "    \"Avg Price (EUR)\": [7.89, 9.15]\n",
    "})\n",
    "\n",
    "# --- Styling (same as before) ---\n",
    "styled_summary = (\n",
    "    cluster_summary.style\n",
    "    .set_caption(\"üìö Cluster Summary ‚Äî Average Features per Group (k = 2)\")\n",
    "    .set_table_styles([\n",
    "        {\"selector\": \"caption\", \n",
    "         \"props\": [(\"text-align\", \"left\"), (\"font-size\", \"16px\"), \n",
    "                   (\"font-weight\", \"bold\"), (\"color\", \"#00c3ff\")]},\n",
    "        {\"selector\": \"table\", \n",
    "         \"props\": [(\"border\", \"2px solid #00c3ff\"), (\"border-radius\", \"8px\"), \n",
    "                   (\"border-collapse\", \"collapse\")]},\n",
    "        {\"selector\": \"th\", \n",
    "         \"props\": [(\"background-color\", \"#1c1c1c\"), (\"color\", \"white\"), \n",
    "                   (\"text-align\", \"center\"), (\"font-size\", \"14px\")]},\n",
    "        {\"selector\": \"td\", \n",
    "         \"props\": [(\"background-color\", \"#505050\"), (\"color\", \"#f2f2f2\"), \n",
    "                   (\"font-size\", \"13px\"), (\"text-align\", \"center\")]}\n",
    "    ])\n",
    "    .hide(axis=\"index\")\n",
    "    .format({\n",
    "        \"Avg Rating\": \"{:.2f}\",\n",
    "        \"Avg Price (EUR)\": \"{:.2f}\"\n",
    "    })\n",
    ")\n",
    "\n",
    "# --- Display ---\n",
    "display(styled_summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book_recommender (uv)",
   "language": "python",
   "name": "book-recommendation-system"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
