{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68329238-301b-4926-898b-23d8902626c5",
   "metadata": {},
   "source": [
    "### üìò Notebook 03 ‚Äî Feature Engineering & Clustering\n",
    "\n",
    "In this notebook, we move from **data preparation** to **unsupervised learning**.  \n",
    "Using the cleaned dataset (`books_final_1000.csv`), we‚Äôll extract key features such as ratings, price, and genre to group similar books with **K-Means clustering**.\n",
    "\n",
    "**Goals:**\n",
    "- Prepare numerical and categorical features  \n",
    "- Apply **K-Means** and evaluate with **Elbow Method** & **Silhouette Score**  \n",
    "- Visualize and interpret clusters for future recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436f659a-f4e5-4af3-a457-08c4452d07dd",
   "metadata": {},
   "source": [
    "### Step 1 ‚Äî Imports & Setup\n",
    "\n",
    "Import core libraries for clustering and visualization,  \n",
    "reload the shared `functions.py` module, and verify that all paths from `config.yaml` are available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd0020d-0dd0-4345-b793-cf114618f2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 1 ‚Äî Imports & Setup \n",
    "# ============================================================\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "\n",
    "# --- Access shared functions ---\n",
    "sys.path.append(\"notebooks\")\n",
    "from functions import load_config, ensure_directories\n",
    "import functions\n",
    "importlib.reload(functions)\n",
    "\n",
    "# --- Additional libraries for ML and visualization ---\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# --- Load configuration from root ---\n",
    "config_path = Path(\"..\") / \"config.yaml\"\n",
    "config = load_config(config_path)\n",
    "\n",
    "# --- Verify folders ---\n",
    "ensure_directories(config[\"paths\"])\n",
    "\n",
    "print(\"‚úÖ Environment ready ‚Äî config loaded and directories verified.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf9a4e9-fb7b-4eff-a38a-6144010179be",
   "metadata": {},
   "source": [
    "### Step 2 ‚Äî Load Final Dataset  \n",
    "\n",
    "Load the cleaned and standardized dataset (`books_final_1000.csv`) generated in the previous notebook.  \n",
    "We‚Äôll inspect its structure, check column types, and verify that all key variables are ready for feature preparation.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3febf18-26d5-4fbb-abe9-bc3221a68bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 2 ‚Äî Load Final Dataset\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Load dataset from data/clean ---\n",
    "data_path = Path(\"..\") / config[\"paths\"][\"data_clean\"] / \"books_final_1000.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"‚úÖ Dataset loaded successfully: {data_path}\")\n",
    "print(f\"Shape: {df.shape}\\n\")\n",
    "\n",
    "# --- Quick overview ---\n",
    "display(df.head(5))\n",
    "\n",
    "# --- Basic info and types ---\n",
    "print(\"\\nüîç DataFrame Info:\")\n",
    "print(df.info())\n",
    "\n",
    "# --- Missing values summary ---\n",
    "missing_summary = df.isna().sum()\n",
    "missing_summary = missing_summary[missing_summary > 0]\n",
    "\n",
    "if not missing_summary.empty:\n",
    "    print(\"\\n‚ö†Ô∏è Missing values summary:\")\n",
    "    print(missing_summary)\n",
    "else:\n",
    "    print(\"\\n‚úÖ No missing values detected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b3587b-bc60-444b-97b0-23dc52c64bb0",
   "metadata": {},
   "source": [
    "### Step 3 ‚Äî Feature Preparation\n",
    "\n",
    "Select relevant features for clustering:\n",
    "- `avg_rating` (numerical)\n",
    "- `price` (numerical)\n",
    "- `genre` (categorical)\n",
    "\n",
    "We‚Äôll:\n",
    "1. Fill missing prices with the median value  \n",
    "2. Encode `genre` using One-Hot Encoding  \n",
    "3. Standardize numerical features with `StandardScaler`  \n",
    "4. Combine all into a clean feature matrix for K-Means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2490fb66-6f28-440f-b9bd-850b6f404913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 3 ‚Äî Feature Preparation\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Select relevant columns ---\n",
    "features = [\"avg_rating\", \"price\", \"genre\"]\n",
    "df_features = df[features].copy()\n",
    "\n",
    "# --- Handle missing values ---\n",
    "# Fill missing prices with median (robust against outliers)\n",
    "median_price = df_features[\"price\"].median()\n",
    "df_features[\"price\"] = df_features[\"price\"].fillna(median_price)\n",
    "\n",
    "print(f\"üí∞ Filled missing 'price' values with median: {median_price:.2f}\")\n",
    "\n",
    "# --- One-Hot Encode 'genre' ---\n",
    "df_encoded = pd.get_dummies(df_features, columns=[\"genre\"], drop_first=True)\n",
    "\n",
    "# --- Standardize numeric columns ---\n",
    "scaler = StandardScaler()\n",
    "numeric_cols = [\"avg_rating\", \"price\"]\n",
    "df_encoded[numeric_cols] = scaler.fit_transform(df_encoded[numeric_cols])\n",
    "\n",
    "# Ensure missing prices are filled before clustering\n",
    "median_price = df[\"price\"].median()\n",
    "df[\"price\"] = df[\"price\"].fillna(median_price)\n",
    "\n",
    "print(f\"‚úÖ Missing prices filled with median: {median_price}\")\n",
    "\n",
    "\n",
    "print(f\"‚úÖ Feature matrix ready for clustering. Shape: {df_encoded.shape}\")\n",
    "\n",
    "# --- Quick preview ---\n",
    "display(df_encoded.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610698bf-5f3d-4739-8d38-971a5d463a8c",
   "metadata": {},
   "source": [
    "### Step 4 ‚Äî K-Means Clustering (Elbow & Silhouette Method)\n",
    "\n",
    "We‚Äôll apply **K-Means clustering** to group similar books based on their features.  \n",
    "To choose the optimal number of clusters (`k`), we‚Äôll use:\n",
    "- the **Elbow Method** (inertia plot), and  \n",
    "- the **Silhouette Score** (cluster separation quality).  \n",
    "\n",
    "This helps identify a balance between compactness and separation of clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d54a59-f572-42d6-b74d-98047b475015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 4 ‚Äî K-Means Clustering (Elbow & Silhouette Method)\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Feature matrix ---\n",
    "X = df_encoded.copy()\n",
    "\n",
    "# --- Initialize lists ---\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "K_range = range(2, 11)  # test k between 2 and 10\n",
    "\n",
    "print(\"üîπ Running K-Means for k = 2 to 10...\\n\")\n",
    "\n",
    "# --- Run K-Means across different k values ---\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X, kmeans.labels_))\n",
    "\n",
    "print(\"‚úÖ K-Means training completed.\")\n",
    "\n",
    "# --- Elbow Method ---\n",
    "fig_elbow, ax1 = plt.subplots(figsize=(6, 4))\n",
    "ax1.plot(K_range, inertias, marker='o', color='steelblue')\n",
    "ax1.set_title(\"Elbow Method ‚Äî K-Means Inertia\")\n",
    "ax1.set_xlabel(\"Number of Clusters (k)\")\n",
    "ax1.set_ylabel(\"Inertia\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Silhouette Scores ---\n",
    "fig_silhouette, ax2 = plt.subplots(figsize=(6, 4))\n",
    "ax2.plot(K_range, silhouette_scores, marker='o', color='orange')\n",
    "ax2.set_title(\"Silhouette Scores by Number of Clusters\")\n",
    "ax2.set_xlabel(\"Number of Clusters (k)\")\n",
    "ax2.set_ylabel(\"Silhouette Score\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Save both plots ---\n",
    "viz_path = Path(\"..\") / \"visualizations\"\n",
    "viz_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "fig_elbow.savefig(viz_path / \"elbow_method_kmeans.png\", dpi=300, bbox_inches=\"tight\")\n",
    "fig_silhouette.savefig(viz_path / \"silhouette_scores.png\", dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "print(f\"üíæ Elbow plot saved ‚Üí {viz_path / 'elbow_method_kmeans.png'}\")\n",
    "print(f\"üíæ Silhouette plot saved ‚Üí {viz_path / 'silhouette_scores.png'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4e8a2d-c5ce-47f6-b262-74367e9610bf",
   "metadata": {},
   "source": [
    "### Step 4.1 ‚Äî Interpretation of Clustering Metrics\n",
    "\n",
    "The **Elbow Method** shows a clear bend between *k = 3* and *k = 4*,  \n",
    "indicating that adding more clusters beyond this point brings little improvement in compactness.  \n",
    "\n",
    "The **Silhouette Scores** confirm that:\n",
    "- *k = 2* yields the highest separation (‚âà 0.75),  \n",
    "  but that configuration is too broad and oversimplifies book diversity.  \n",
    "- *k = 3 ‚Äì 4* offers a better trade-off between cohesion (books inside each cluster are similar)  \n",
    "  and separation (clusters differ from each other).  \n",
    "\n",
    "üìä **Decision:** We‚Äôll proceed with **k = 3 clusters**,  \n",
    "as it balances interpretability and internal consistency.\n",
    "\n",
    "üß† **What we‚Äôre analyzing:**  \n",
    "Each book is represented by numerical and categorical features such as  \n",
    "`avg_rating`, `genre`, and `price`.  \n",
    "K-Means groups books with similar characteristics into clusters ‚Äî  \n",
    "helping us identify **reader preference patterns** or **content similarities**  \n",
    "that could later power a **recommendation system**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d92e84-d200-4741-87b2-0c906dd5aee4",
   "metadata": {},
   "source": [
    "### Step 5 ‚Äî Apply Final K-Means & Visualize Clusters (PCA 2D Projection)\n",
    "\n",
    "Now that we‚Äôve decided on **k = 3 clusters**, we‚Äôll train the final K-Means model.  \n",
    "Then, we‚Äôll apply **Principal Component Analysis (PCA)** to reduce the high-dimensional\n",
    "feature space into **two components**, allowing us to visualize the book clusters in 2D.  \n",
    "\n",
    "This helps identify group patterns ‚Äî for example,  \n",
    "books that share similar ratings, prices, or genres might fall close together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b2bb50-88d5-4239-9aa2-2c9dbedf80fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 5 ‚Äî Apply Final K-Means & Visualize Clusters (Enhanced)\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Final number of clusters ---\n",
    "k_final = 3\n",
    "print(f\"üè∑Ô∏è Applying final K-Means model with k = {k_final}...\\n\")\n",
    "\n",
    "# --- Scale features ---\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_encoded)\n",
    "\n",
    "# --- Train K-Means ---\n",
    "kmeans_final = KMeans(n_clusters=k_final, random_state=42, n_init=10)\n",
    "df[\"cluster\"] = kmeans_final.fit_predict(X_scaled)\n",
    "\n",
    "# --- PCA for visualization ---\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "pca_components = pca.fit_transform(X_scaled)\n",
    "df[\"pca_1\"] = pca_components[:, 0]\n",
    "df[\"pca_2\"] = pca_components[:, 1]\n",
    "\n",
    "# --- Enhanced Visualization ---\n",
    "fig_pca, ax = plt.subplots(figsize=(8,6))\n",
    "sns.scatterplot(\n",
    "    data=df,\n",
    "    x=\"pca_1\", y=\"pca_2\",\n",
    "    hue=\"cluster\",\n",
    "    palette=\"Set2\",\n",
    "    s=60,\n",
    "    alpha=0.85,\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=0.6,\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title(\"Book Clusters ‚Äî PCA 2D Projection (k = 3)\", fontsize=13, pad=10)\n",
    "ax.set_xlabel(\"Principal Component 1\")\n",
    "ax.set_ylabel(\"Principal Component 2\")\n",
    "ax.legend(title=\"Cluster\", loc=\"upper right\", fontsize=9)\n",
    "ax.grid(alpha=0.3, linestyle=\"--\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Save plot for presentation ---\n",
    "viz_path = Path(\"..\") / \"visualizations\"\n",
    "viz_path.mkdir(parents=True, exist_ok=True)\n",
    "fig_pca.savefig(viz_path / \"pca_clusters_k3.png\", dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "print(f\"‚úÖ Clustering completed. {df['cluster'].nunique()} clusters created.\")\n",
    "print(f\"üíæ PCA cluster visualization saved ‚Üí {viz_path / 'pca_clusters_k3.png'}\\n\")\n",
    "\n",
    "# --- Preview sample ---\n",
    "display(df[[\"title\", \"author\", \"avg_rating\", \"genre\", \"price\", \"cluster\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7170f744-bce7-4ec8-938c-bf6905a6b626",
   "metadata": {},
   "source": [
    "### Step 5.1 ‚Äî Analyze Cluster Centroids\n",
    "\n",
    "Let‚Äôs inspect the numerical centroids of each cluster to understand\n",
    "how books are grouped ‚Äî for example, by their average rating or price.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c501521-88d8-4741-a9aa-7e914380c334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 5.1 ‚Äî Analyze Cluster Centroids\n",
    "# ============================================================\n",
    "\n",
    "cluster_centroids = (\n",
    "    df.groupby(\"cluster\")\n",
    "    .agg({\n",
    "        \"avg_rating\": \"mean\",\n",
    "        \"price\": \"mean\",\n",
    "        \"genre\": lambda x: x.mode().iloc[0] if not x.mode().empty else \"Unknown\"\n",
    "    })\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "print(\" Cluster Centroids Summary:\\n\")\n",
    "display(cluster_centroids)\n",
    "\n",
    "print(\"\\n Interpretation Guide:\")\n",
    "print(\"- avg_rating ‚Üí Average book rating per cluster.\")\n",
    "print(\"- price ‚Üí Mean price, useful to detect premium vs. budget titles.\")\n",
    "print(\"- genre ‚Üí Most common genre in each cluster.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78ebd9b-0528-49a2-afdb-ba80d2914a60",
   "metadata": {},
   "source": [
    "## Step 5.2 ‚Äî Cluster Interpretation & Summary\n",
    "\n",
    " üß≠ Interpretation\n",
    "\n",
    "- **Cluster 0 ‚Äî ‚ÄúYouth-Oriented Titles‚Äù**  \n",
    "  Books in this group are mainly **Juvenile Fiction**, slightly higher in rating, and moderately priced.  \n",
    "  They likely attract younger readers and reflect more accessible, engaging narratives.\n",
    "\n",
    "- **Cluster 1 ‚Äî ‚ÄúGeneral Fiction Classics‚Äù**  \n",
    "  Dominated by **Fiction**, this cluster includes a broad mix of popular titles and literary works.  \n",
    "  Prices are a bit higher on average, suggesting the presence of well-known or premium editions.\n",
    "\n",
    "- **Cluster 2 ‚Äî ‚ÄúSpecialized Literature‚Äù**  \n",
    "  This cluster groups more niche genres such as *Governesses in Literature*.  \n",
    "  These books maintain solid ratings but cater to smaller, topic-focused audiences.\n",
    "\n",
    "---\n",
    "\n",
    "üí¨ Overall Insight\n",
    "\n",
    "Across all clusters, average ratings remain consistently high (‚âà 4.1‚Äì4.2),  \n",
    "indicating that Goodreads‚Äô most popular books share strong reader approval.  \n",
    "Price variation is modest ‚Äî meaning **genre and thematic focus** play a greater role in the clustering than cost.  \n",
    "This insight will be valuable for the **next phase: building the recommendation engine**,  \n",
    "where similar clusters can guide personalized book suggestions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db1fc3c-0a01-4b19-9108-35d25c40e2c4",
   "metadata": {},
   "source": [
    "## Step 6 ‚Äî Export Final Clustered Dataset\n",
    "\n",
    "We‚Äôll now export the final dataset including the cluster labels (`cluster`)\n",
    "and PCA coordinates (`pca_1`, `pca_2`) for visualization and further analysis.  \n",
    "This dataset can be used in **Tableau**, **Power BI**, or in the next notebook\n",
    "for building the **Recommendation System**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b9987a-a80a-46fa-a765-d31158e27ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 6 ‚Äî Export Final Clustered Dataset & Cluster Summary\n",
    "# ============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# --- Define export paths ---\n",
    "data_clean_path = Path(\"..\") / config[\"paths\"][\"data_clean\"]\n",
    "viz_path = Path(\"..\") / \"visualizations\"\n",
    "data_clean_path.mkdir(parents=True, exist_ok=True)\n",
    "viz_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "final_cluster_path = data_clean_path / \"books_clustered_final.csv\"\n",
    "\n",
    "# --- Select relevant columns ---\n",
    "export_cols = [\n",
    "    \"title\",\n",
    "    \"author\",\n",
    "    \"avg_rating\",\n",
    "    \"genre\",\n",
    "    \"price\",\n",
    "    \"currency\",\n",
    "    \"cover_url\",\n",
    "    \"link\",\n",
    "    \"cluster\",\n",
    "    \"pca_1\",\n",
    "    \"pca_2\"\n",
    "]\n",
    "\n",
    "# --- Save dataset ---\n",
    "df[export_cols].to_csv(final_cluster_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"üíæ Final clustered dataset saved successfully ‚Üí {final_cluster_path.resolve()}\")\n",
    "\n",
    "# --- Quick preview ---\n",
    "print(\"\\nüìò Sample of exported dataset:\")\n",
    "display(df[export_cols].head(10))\n",
    "\n",
    "# ============================================================\n",
    "# üìä Cluster Summary (for visualization or presentation)\n",
    "# ============================================================\n",
    "\n",
    "cluster_summary = (\n",
    "    df.groupby(\"cluster\")\n",
    "    .agg({\n",
    "        \"avg_rating\": \"mean\",\n",
    "        \"price\": \"mean\",\n",
    "        \"genre\": lambda x: x.mode().iloc[0] if not x.mode().empty else \"Unknown\"\n",
    "    })\n",
    "    .round(2)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(\"\\nüìó Cluster Summary:\")\n",
    "display(cluster_summary)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7aeb7b-d531-4519-88a4-36b1a508c831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# üìä Cluster Summary Table ‚Äî Final Styled Version\n",
    "# ============================================================\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "\n",
    "# --- Cluster centroids summary ---\n",
    "cluster_summary = pd.DataFrame({\n",
    "    \"Cluster\": [0, 1, 2],\n",
    "    \"Dominant Genre\": [\"Juvenile Fiction\", \"Fiction\", \"Governesses in Literature\"],\n",
    "    \"Avg Rating\": [4.18, 4.10, 4.16],\n",
    "    \"Avg Price (EUR)\": [8.66, 9.25, 8.99],\n",
    "})\n",
    "\n",
    "# --- Styling ---\n",
    "styled_summary = (\n",
    "    cluster_summary.style\n",
    "    .set_caption(\"üìö Cluster Summary ‚Äî Average Features per Group\")\n",
    "    .set_table_styles([\n",
    "    {\"selector\": \"caption\", \n",
    "     \"props\": [(\"text-align\", \"left\"), (\"font-size\", \"16px\"), (\"font-weight\", \"bold\"), (\"color\", \"#00c3ff\")]},\n",
    "    {\"selector\": \"table\", \n",
    "     \"props\": [(\"border\", \"2px solid #00c3ff\"), (\"border-radius\", \"8px\"), (\"border-collapse\", \"collapse\")]},\n",
    "    {\"selector\": \"th\", \n",
    "     \"props\": [(\"background-color\", \"#1c1c1c\"), (\"color\", \"white\"), (\"text-align\", \"center\"), (\"font-size\", \"14px\")]},\n",
    "    {\"selector\": \"td\", \n",
    "     \"props\": [(\"background-color\", \"#505050\"), (\"color\", \"#f2f2f2\"), (\"font-size\", \"13px\"), (\"text-align\", \"center\")]}\n",
    "])\n",
    "    .hide(axis=\"index\")\n",
    "    .format({\n",
    "        \"Avg Rating\": \"{:.2f}\",\n",
    "        \"Avg Price (EUR)\": \"{:.2f}\"\n",
    "    })\n",
    ")\n",
    "\n",
    "# --- Display ---\n",
    "display(styled_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d624561-13bb-46e2-a0e3-4a170d8e5aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book_recommender (uv)",
   "language": "python",
   "name": "book-recommendation-system"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
