{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "610bb5d3-5748-45f7-a905-d382746a41b3",
   "metadata": {},
   "source": [
    "## Step 1 — Load Configuration & Base Dataset\n",
    "\n",
    "In this step, we load the main configuration file (`config.yaml`) to access all project paths, and then import the base dataset `books_clustered_final.csv` from the `data/clean` directory.\n",
    "\n",
    "This dataset contains the books used for clustering in the previous step. It will serve as the foundation for enriching missing information such as ratings and genres using external data sources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e3f9a2-a5fc-4753-82a8-f5e5ebad92a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 1 — Load Configuration & Base Dataset\n",
    "# ============================================================\n",
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from functions import load_config, ensure_directories\n",
    "\n",
    "# --- Load configuration from project root ---\n",
    "config_path = Path(\"..\") / \"config.yaml\"\n",
    "config = load_config(config_path)\n",
    "\n",
    "# --- Ensure all folders exist ---\n",
    "ensure_directories(config[\"paths\"])\n",
    "\n",
    "# --- Load base dataset ---\n",
    "data_clean_path = Path(\"..\") / config[\"paths\"][\"data_clean\"]\n",
    "input_file = data_clean_path / \"books_clustered_final.csv\"\n",
    "\n",
    "df_main = pd.read_csv(input_file)\n",
    "\n",
    "print(f\"Dataset loaded successfully: {df_main.shape}\")\n",
    "df_main.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13d23cd-1f4d-4569-a8fe-c66fb4a38ab9",
   "metadata": {},
   "source": [
    "## Step 2 — Load Goodreads Dataset (Kaggle goodbooks-10k)\n",
    "\n",
    "In this step, we load the `books.csv` file from the Kaggle dataset “goodbooks-10k”.  \n",
    "This dataset contains around 10 000 books with standardized metadata such as title, author, average rating, number of ratings, and publication year.  \n",
    "It is a lighter and cleaner dataset than the previous BrightData version and aligns well with our book titles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87a5b40-47e4-4478-9532-06582f261226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 2 — Load Goodreads Dataset (Kaggle goodbooks-10k)\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Define path (using config paths)\n",
    "data_raw_path = Path(\"..\") / \"data\" / \"raw\"\n",
    "goodreads_file = data_raw_path / \"books.csv\"  # rename your downloaded books.csv to this\n",
    "\n",
    "# Load dataset\n",
    "df_goodreads = pd.read_csv(goodreads_file)\n",
    "print(f\"Kaggle Goodreads dataset loaded: {df_goodreads.shape}\")\n",
    "\n",
    "# Display available columns\n",
    "print(\"Columns:\", df_goodreads.columns.tolist())\n",
    "\n",
    "# Preview\n",
    "df_goodreads.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6fc00c-df21-4fed-b973-ee43c2d9dc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_goodreads.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a97aec-d935-4e36-80a8-073efc2e4326",
   "metadata": {},
   "source": [
    "## Step 3 — Preprocess Titles & Authors for Merging\n",
    "\n",
    "Before merging both datasets, we standardize and align the column names used as matching keys.\n",
    "\n",
    "In the Kaggle dataset, the relevant columns are:\n",
    "- `title` → book title  \n",
    "- `authors` → author name(s)  \n",
    "- `average_rating` → Goodreads average rating  \n",
    "- `ratings_count` → total number of ratings  \n",
    "- `original_publication_year` → publication year  \n",
    "- `image_url` → cover image\n",
    "\n",
    "We will:\n",
    "1. Keep only these relevant columns.  \n",
    "2. Rename them for consistency.  \n",
    "3. Normalize `title` and `author` text to lowercase for reliable matching.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed80f06-33c7-4450-830e-2a344f783b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 3 — Preprocess Titles & Authors for Merging\n",
    "# ============================================================\n",
    "\n",
    "# Select and rename relevant columns\n",
    "cols_to_keep = [\n",
    "    \"title\",\n",
    "    \"authors\",\n",
    "    \"average_rating\",\n",
    "    \"ratings_count\",\n",
    "    \"original_publication_year\",\n",
    "    \"image_url\"\n",
    "]\n",
    "\n",
    "df_goodreads = df_goodreads[cols_to_keep].rename(columns={\n",
    "    \"authors\": \"author\",\n",
    "    \"average_rating\": \"avg_rating_goodreads\",\n",
    "    \"ratings_count\": \"ratings_count_goodreads\",\n",
    "    \"original_publication_year\": \"published_year_goodreads\",\n",
    "    \"image_url\": \"cover_url_goodreads\"\n",
    "})\n",
    "\n",
    "# Normalize titles and authors in both datasets\n",
    "df_main[\"title_clean\"] = df_main[\"title\"].str.lower().str.strip()\n",
    "df_main[\"author_clean\"] = df_main[\"author\"].str.lower().str.strip()\n",
    "\n",
    "df_goodreads[\"title_clean\"] = df_goodreads[\"title\"].str.lower().str.strip()\n",
    "df_goodreads[\"author_clean\"] = df_goodreads[\"author\"].str.lower().str.strip()\n",
    "\n",
    "print(\"Columns prepared for merging:\")\n",
    "print(df_goodreads.head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea56c7b0-e0b9-40ee-b26b-586891a1fd68",
   "metadata": {},
   "source": [
    "## Step 4 — Merge Datasets (Left Join by Title & Author)\n",
    "\n",
    "In this step, we merge our main dataset (`books_clustered_final.csv`) with the Kaggle Goodreads dataset (`books.csv`)\n",
    "using the normalized columns `title_clean` and `author_clean` as join keys.\n",
    "\n",
    "This allows us to enrich our dataset with:\n",
    "- More accurate average ratings from Goodreads\n",
    "- Total number of ratings (`ratings_count_goodreads`)\n",
    "- Publication year\n",
    "- Cover image URL\n",
    "\n",
    "We use a **left join** to keep all entries from our main dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3792c533-3d3f-4f02-9e49-378f5843c75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 4 — Merge Datasets (Left Join by Title & Author)\n",
    "# ============================================================\n",
    "\n",
    "# Perform left join\n",
    "df_merged = pd.merge(\n",
    "    df_main,\n",
    "    df_goodreads[\n",
    "        [\n",
    "            \"title_clean\",\n",
    "            \"author_clean\",\n",
    "            \"avg_rating_goodreads\",\n",
    "            \"ratings_count_goodreads\",\n",
    "            \"published_year_goodreads\",\n",
    "            \"cover_url_goodreads\"\n",
    "        ]\n",
    "    ],\n",
    "    on=[\"title_clean\", \"author_clean\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(f\"Merge completed: {df_merged.shape}\")\n",
    "\n",
    "# Display sample of enriched data\n",
    "df_merged[\n",
    "    [\"title\", \"author\", \"avg_rating\", \"avg_rating_goodreads\", \"ratings_count_goodreads\"]\n",
    "].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d53456-6576-48c3-9e8b-a00836a5e1ba",
   "metadata": {},
   "source": [
    "## Step 5 — Replace Imputed Ratings and Save Enriched Dataset\n",
    "\n",
    "In this step, we replace the imputed values from our main dataset\n",
    "with the real Goodreads data obtained from the merge.\n",
    "\n",
    "Specifically:\n",
    "- Replace `avg_rating` values equal to 4.11 with the Goodreads rating when available.\n",
    "- Add the Goodreads `ratings_count` as a new feature.\n",
    "- Save the enriched dataset as `books_final_enriched.csv` in the `data/clean` folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b62ad99-d70f-49b9-8c8d-67f482e74cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 5 — Safely Replace Imputed Ratings and Save Enriched Dataset\n",
    "# ============================================================\n",
    "\n",
    "from functions import save_dataset\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Create a copy to be safe ---\n",
    "df_enriched = df_merged.copy()\n",
    "\n",
    "# Replace only imputed ratings (4.11) with Goodreads ratings when available\n",
    "mask_replace = (\n",
    "    df_enriched[\"avg_rating\"].round(2) == 4.11\n",
    ") & (df_enriched[\"avg_rating_goodreads\"].notna())\n",
    "\n",
    "df_enriched.loc[mask_replace, \"avg_rating\"] = df_enriched.loc[\n",
    "    mask_replace, \"avg_rating_goodreads\"\n",
    "]\n",
    "\n",
    "# Keep Goodreads ratings_count as a new column (optional feature)\n",
    "df_enriched[\"ratings_count\"] = df_enriched[\"ratings_count_goodreads\"]\n",
    "\n",
    "# Remove helper columns but keep your core structure intact\n",
    "df_enriched = df_enriched.drop(columns=[\"avg_rating_goodreads\", \"ratings_count_goodreads\"])\n",
    "\n",
    "# Save the enriched dataset\n",
    "output_path = Path(\"..\") / \"data\" / \"clean\" / \"books_final_enriched.csv\"\n",
    "save_dataset(df_enriched, output_path)\n",
    "\n",
    "# --- Summary ---\n",
    "print(\"✅ Enriched dataset saved safely → books_final_enriched.csv\")\n",
    "print(f\"Ratings replaced (4.11 → Goodreads): {mask_replace.sum()}\")\n",
    "print(df_enriched[[\"title\", \"author\", \"avg_rating\", \"ratings_count\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0826dd54-bc56-42d8-8982-eccc17dd5f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 6 — Summary & Quality Check\n",
    "\n",
    "In this final step, we evaluate how much the dataset improved after enrichment.\n",
    "\n",
    "We will:\n",
    "- Count how many books had their imputed `avg_rating` (4.11) replaced with real Goodreads values.\n",
    "- Compare the average rating before and after enrichment.\n",
    "- Show basic statistics for the new `ratings_count` feature.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book_recommender (uv)",
   "language": "python",
   "name": "book-recommendation-system"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
