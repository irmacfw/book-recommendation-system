# ğŸ“š Book Recommendation System  
*Ironhack Data Analytics Bootcamp â€” Week 10 Project*  
*Author: Irma FernÃ¡ndez Wiechers*  

---

## ğŸ¯ Project Overview

This project aims to build a **Book Recommendation System** using real data from **Goodreads** and **Google Books API**.  
It combines skills in **web scraping, data cleaning, enrichment, and clustering** â€” simulating a real-world end-to-end data science pipeline.

The system ultimately recommends books based on **content similarity** (e.g. rating, genre, author, and publication year).

---

## ğŸ§­ Project Workflow

| Phase | Description | Output |
|:--|:--|:--|
| **1. Data Acquisition** | Scraped ~1000 books from Goodreads (Best Books Ever list) across 10 pages. | `books_clean.csv`, `books_clean_enriched_1000.csv` |
| **2. API Enrichment** | Used Google Books API to enrich missing metadata (genre, published year, price, cover URL). | `books_enriched.csv` |
| **3. Data Cleaning** | Removed duplicates, standardized text fields, and extracted numeric ratings. | `books_clean.csv` |
| **4. Data Combination** | Merged both datasets (web + API) into a final 1000-book dataset. | `books_final_1000.csv` |
| **5. Exploratory Analysis** | Visualized distribution of ratings, genres, prices, and publication years. | EDA plots |
| **6. Standardization** | Rounded numeric values, formatted text alignment, and verified structure. | `books_final_1000.csv` |
| **7. Feature Engineering** | (Next) Prepare features for clustering and model training. | `books_features.csv` |
| **8. Modeling & Deployment** | (Next) Build a Streamlit prototype for book recommendations. | `app/` |

---

## ğŸ§© Data Sources

| Source | Type | Description |
|:--|:--|:--|
| [Goodreads](https://www.goodreads.com/list/show/1.Best_Books_Ever) | Web scraping | Book titles, authors, ratings, links |
| [Google Books API](https://developers.google.com/books) | API | Genres, publication dates, cover URLs, prices |

---

## ğŸ§  Key Learnings

- Ethical web scraping and responsible request handling (`time.sleep`, headers)
- API integration with fallback logic and exception handling
- Data cleaning and standardization using `pandas`
- Combining heterogeneous sources into a unified dataset
- Visualization of real-world book data with `matplotlib` and `seaborn`
- Preparing for unsupervised learning (K-Means, PCA)

---

## ğŸ“ Repository Structure
```
book-recommendation-system/
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # Raw scraped and API data
â”‚ â””â”€â”€ clean/ # Cleaned and enriched datasets
â”‚
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ 01_web_scraping_goodreads.ipynb
â”‚ â”œâ”€â”€ 02_web_scraping_goodreads_part2.ipynb
â”‚ â””â”€â”€ 03_book_features_clustering.ipynb
â”‚
â”œâ”€â”€ models/ # Trained models (future)
â”œâ”€â”€ app/ # Streamlit deployment files (future)
â”œâ”€â”€ utils/ # Helper scripts
â”œâ”€â”€ functions.py # Reusable functions
â”œâ”€â”€ config.yaml # Project configuration
â””â”€â”€ README.md # (this notebook section)
```

---

## ğŸ“Š Current Output Summary (as of Notebook 02)

**First dataset:** (493, 9)  
**Second dataset:** (497, 8)  
âœ… **Combined dataset shape:** (990, 8)  
ğŸ‘©â€ğŸ’» **Unique authors:** 614  

**Missing values summary:**

| Column | Missing Values |
|:--|--:|
| genre | 123 |
| price | 529 |
| currency | 529 |
| cover_url | 96 |

ğŸ’¾ **Final dataset:**  
`data/clean/books_final_1000.csv`

---

## ğŸš€ Next Steps (Notebook 03)

- Load and preprocess the final dataset  
- Perform feature extraction (numeric + text features)
- Apply **K-Means clustering** to group similar books  
- Visualize clusters using **PCA / t-SNE**
- Build a **content-based recommendation system**

---

## ğŸ§‘â€ğŸ’» Tech Stack

- **Python 3.11**
- **Libraries:** pandas, numpy, requests, BeautifulSoup, tqdm, matplotlib, seaborn, scikit-learn  
- **Deployment:** Streamlit (prototype stage)
- **Version Control:** Git / GitHub

---
---

## ğŸ–¥ï¸ Project Presentation

You can explore the visual summary of this project in the following Google Slides presentation:

ğŸ“ **[Book Recommendation System â€” Presentation](https://docs.google.com/presentation/d/1E7G5gAWvXtJ8QqcWSpAUfGRWLJ3w96kZmLjyGypRF10/edit?usp=sharing)**

---

*The presentation summarizes the full pipeline: from data collection and enrichment to clustering insights and the upcoming Streamlit app for book exploration.*


## ğŸ’¬ Author

**Irma FernÃ¡ndez Wiechers**  
Data Analyst | Ironhack Berlin 2025  
ğŸ“ Based in Germany ğŸ‡©ğŸ‡ª  
ğŸ’¼ Background: Insurance brokerage, anti-money laundering, and data analytics  
